{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Spark...\n",
      "Loading file  ./ratings_train.csv ...\n",
      "Loading file  ./movies.csv ...\n",
      "Parsing ratings...\n",
      "Parsing movies...\n",
      "Caching ratings...\n",
      "Create ratings dataframe...\n",
      "Create movies dataframe...\n",
      "Creating ratings relation map...\n",
      "Filtering ratings map, and calculating ratings distance...\n",
      "Calculating user relation similarity...\n",
      "Creating list of users...\n",
      "Caching list of users...\n",
      "Relating all users to all movies to map suggestions...\n",
      "Mapping all ratings to movies...\n",
      "Add user similarity values to ratings...\n",
      "Expanding ratings based on user similarity...\n",
      "Normalizing expanded ratings...\n",
      "Creating list of ratings to print...\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Define some constants\n",
    "RATING_MIN = 0.5\n",
    "RATING_MAX = 5.0\n",
    "RATING_RANGE = RATING_MAX - RATING_MIN\n",
    "\n",
    "# Enable crossjoins\n",
    "print(\"Configuring Spark...\")\n",
    "spark.conf.set(\"spark.sql.crossJoin.enabled\", True)\n",
    "\n",
    "# Define some helper functions\n",
    "def readCSV(fname, removeHeader=False, separator=','):\n",
    "    print(\"Loading file \", fname, \"...\")\n",
    "    rdd = sc.textFile(fname)\n",
    "    if removeHeader:\n",
    "        firstline = rdd.first()\n",
    "        rdd = rdd.filter(lambda x: x != firstline)\n",
    "    return rdd.map(lambda x: x.split(separator))\n",
    "\n",
    "# Load the movies and ratings database\n",
    "ratings = readCSV(\"./ratings_train.csv\", removeHeader=True)\n",
    "movies = readCSV(\"./movies.csv\", removeHeader=True)\n",
    "\n",
    "# Parse the rating data\n",
    "# [user_id, movie_id, rating, timestamp]\n",
    "print(\"Parsing ratings...\")\n",
    "ratings = ratings.map(lambda x: x[0].split('::'))\n",
    "\n",
    "# Parse the movie genres\n",
    "# [id, name, genres[]]\n",
    "print(\"Parsing movies...\")\n",
    "movies = movies.map(lambda x: [x[0], x[1], x[2].split('|')])\n",
    "\n",
    "# Create a dataframe for the ratings\n",
    "print(\"Create ratings dataframe...\")\n",
    "ratings_df = spark.createDataFrame(ratings, ['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Cache the ratings\n",
    "print(\"Caching ratings dataframe...\")\n",
    "ratings_df = ratings_df.cache()\n",
    "\n",
    "# TODO: Remove this query\n",
    "#client_ratings_df = ratings_df.filter(ratings_df.user_id == client_id).alias(\"client\")\n",
    "# TODO: Remove this query\n",
    "#user_ratings_df = ratings_df.filter(ratings_df.user_id != client_id).alias(\"other\")\n",
    "\n",
    "# Create a dataframe for the movies, and filter it\n",
    "print(\"Create movies dataframe...\")\n",
    "movies_df = spark.createDataFrame(\\\n",
    "                                  movies,\\\n",
    "                                  ['id', 'name', 'genres'])\\\n",
    "    .select(\\\n",
    "            \"id\",\\\n",
    "            \"name\")\\\n",
    "    .alias(\"movies\")\n",
    "\n",
    "# Cache list of movies\n",
    "print(\"Caching movies dataframe...\")\n",
    "movies_df = movies_df.cache()\n",
    "\n",
    "# Join the movies watched by the client and the other user\n",
    "print(\"Creating ratings relation map...\")\n",
    "client_df = ratings_df.alias(\"client\");\n",
    "other_df = ratings_df.alias(\"other\");\n",
    "ratings_map = client_df\\\n",
    "    .join(other_df,\\\n",
    "          on = [col(\"client.movie_id\") == col(\"other.movie_id\"),\\\n",
    "                col(\"client.user_id\") != col(\"other.user_id\")],\\\n",
    "          how = \"inner\")\n",
    "\n",
    "# Determine the rating distance for each user/movie pair, and normalize it\n",
    "print(\"Filtering ratings map, and calculating ratings distance...\")\n",
    "ratings_map = ratings_map.select(\\\n",
    "                 col(\"client.user_id\").alias(\"sim_client_user_id\"),\\\n",
    "                 col(\"other.user_id\").alias(\"sim_other_user_id\"),\\\n",
    "                 \"client.movie_id\",\\\n",
    "                 (abs(col(\"client.rating\") - col(\"other.rating\")) - RATING_RANGE / 2).alias(\"rating_dist_norm\")\\\n",
    "                )\n",
    "\n",
    "# Cache the ratings map\n",
    "#print(\"Caching ratings map...\")\n",
    "#ratings_map = ratings_map.cache()\n",
    "\n",
    "## Create a list of users\n",
    "print(\"Creating list of users...\")\n",
    "user_list = ratings_df.select(col(\"user_id\").alias(\"list_user_id\")).distinct()\n",
    "#user_list_df = user_list_df.where(col(\"list_user_id\") == users_similarity.first().sim_client_user_id)\n",
    "\n",
    "# Cache the list of users\n",
    "print(\"Caching list of users...\")\n",
    "user_list = user_list.cache()\n",
    "\n",
    "# Calculate the user relation similarity\n",
    "print(\"Calculating user relation similarity...\")\n",
    "users_similarity = ratings_map\\\n",
    "    .groupBy(\\\n",
    "             \"sim_client_user_id\",\\\n",
    "             \"sim_other_user_id\")\\\n",
    "    .agg(\\\n",
    "         sum(\"rating_dist_norm\")\\\n",
    "             .alias(\"similarity\"))\\\n",
    "    .alias(\"similarity\")\n",
    "    \n",
    "# Cache the user similarities\n",
    "#print(\"Caching user similarities...\")\n",
    "#user_similarity = user_similarity.cache()\n",
    "\n",
    "# Join all movies to all users \n",
    "print(\"Relating all users to all movies to map suggestions...\")\n",
    "suggestion_map = user_list.join(\\\n",
    "                                movies_df.select(\\\n",
    "                                                 col(\"id\").alias(\"sug_movie_id\")\\\n",
    "                                                ),\\\n",
    "                                on = col(\"sug_movie_id\") != True,\\\n",
    "                                how = \"inner\")\n",
    "\n",
    "# Map all ratings to movies\n",
    "print(\"Mapping all ratings to movies...\")\n",
    "suggestion_map = suggestion_map.join(ratings_df,\\\n",
    "                               on = [col(\"sug_movie_id\") == col(\"movie_id\"),\\\n",
    "                                     col(\"list_user_id\") != col(\"user_id\")],\\\n",
    "                               how = \"inner\")\n",
    "\n",
    "# Add user similarity values\n",
    "print(\"Add user similarity values to ratings...\")\n",
    "suggestion_map = suggestion_map.join(\\\n",
    "                               users_similarity,\\\n",
    "                               on = [col(\"list_user_id\") == col(\"sim_client_user_id\"),\\\n",
    "                                    col(\"user_id\") == col(\"sim_other_user_id\")],\\\n",
    "                              how = \"inner\")\n",
    "\n",
    "# Multiply the rating values by their similarity\n",
    "print(\"Expanding ratings based on user similarity...\")\n",
    "suggestion_map = suggestion_map\\\n",
    "    .select(\\\n",
    "            \"*\",\\\n",
    "            (col(\"rating\") * col(\"similarity\"))\\\n",
    "                .alias(\"rating_mul\"))\n",
    "\n",
    "# Normalize the expanded rating values\n",
    "print(\"Normalizing expanded ratings...\")\n",
    "suggestion_map = suggestion_map\\\n",
    "    .groupBy(\"list_user_id\", \"sug_movie_id\")\\\n",
    "    .agg((ceil((sum(\"rating_mul\") / sum(\"similarity\")) * 2) / 2).alias(\"rating_norm\"))\n",
    "    \n",
    "# Cache the normalized ratings\n",
    "suggestion_map = suggestion_map.cache()\n",
    "\n",
    "# Create and output a list of ratings\n",
    "print(\"Creating list of ratings to print...\")\n",
    "suggestion_map.sort(desc(\"rating_norm\")).show(10000)\n",
    "\n",
    "print(\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Spark...\n",
      "Loading file  ./movies.csv ...\n",
      "Loading file  ./ratings_train.csv ...\n",
      "First movie: ['1', 'Toy Story (1995)', 'Adventure|Animation|Children|Comedy|Fantasy']\n",
      "First rating: ['11973::11::3.0::943354625']\n",
      "First movie, processed: ['1', 'Toy Story (1995)', ['Adventure', 'Animation', 'Children', 'Comedy', 'Fantasy']]\n",
      "First rating, processed: ['11973', '11', '3.0', '943354625']\n",
      "Caching ratings...\n",
      "user_ratings_df:\n",
      "aaa:\n",
      "users_similarity:\n",
      "Creating list of users...\n",
      "user_list_df:\n",
      "suggestions:\n",
      "suggestions2:\n",
      "suggestions3:\n",
      "suggestions4:\n",
      "suggestions5:\n",
      "suggestions6:\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Define some constants\n",
    "RATING_MIN = 0.5\n",
    "RATING_MAX = 5.0\n",
    "RATING_RANGE = RATING_MAX - RATING_MIN\n",
    "\n",
    "# Enable crossjoins\n",
    "print(\"Configuring Spark...\")\n",
    "spark.conf.set(\"spark.sql.crossJoin.enabled\", True)\n",
    "\n",
    "# Define some helper functions\n",
    "def readCSV(fname, removeHeader=False, separator=','):\n",
    "    print(\"Loading file \", fname, \"...\")\n",
    "    rdd = sc.textFile(fname)\n",
    "    if removeHeader:\n",
    "        firstline = rdd.first()\n",
    "        rdd = rdd.filter(lambda x: x != firstline)\n",
    "    return rdd.map(lambda x: x.split(separator))\n",
    "\n",
    "# Load the movies and ratings database\n",
    "movies = readCSV(\"./movies.csv\", removeHeader=True)\n",
    "ratings = readCSV(\"./ratings_train.csv\", removeHeader=True)\n",
    "\n",
    "# Print the first entries to debug whether the data is loaded correctly\n",
    "print(\"First movie:\", movies.first())\n",
    "print(\"First rating:\", ratings.first())\n",
    "\n",
    "# Parse the movie genres\n",
    "# [id, name, genres[]]\n",
    "movies = movies.map(lambda x: [x[0], x[1], x[2].split('|')])\n",
    "print(\"First movie, processed:\", movies.first())\n",
    "\n",
    "# Parse the rating data\n",
    "# [user_id, movie_id, rating, timestamp]\n",
    "ratings = ratings.map(lambda x: x[0].split('::'))\n",
    "print(\"First rating, processed:\", ratings.first())\n",
    "\n",
    "print(\"Caching ratings...\")\n",
    "ratings = ratings.cache()\n",
    "\n",
    "# Select the user to suggest movies for\n",
    "client = ratings.first();\n",
    "client_id = client[0];\n",
    "#print(\"Determining movie suggestions for user\", client[0], \"...\")\n",
    "#\n",
    "#def addToSet(input_set, value):\n",
    "#    input_set.add(value)\n",
    "#    return input_set\n",
    "#\n",
    "## Group all ratings by their user keys\n",
    "#user_ratings = ratings.map(lambda x: (x[0], tuple(x[1:])))\\\n",
    "#                   .aggregateByKey(\\\n",
    "#                       set(), # initial value for an accumulator \\\n",
    "#                       addToSet, # function to add a value to an accumulator \\\n",
    "#                       lambda r1, r2: r1.union(r2) # function to merge two accumulators \\\n",
    "#                   )\n",
    "#\n",
    "## Get the ratings for the selected client\n",
    "#client_ratings = user_ratings.lookup(client_id)\n",
    "#print(\"Client ratings:\", client_ratings)\n",
    "#\n",
    "## The selected client must not be in the list of user ratings\n",
    "#user_ratings = user_ratings.filter(lambda x: x[0] != client_id)\n",
    "#\n",
    "#print(\"Caching user ratings...\")\n",
    "#user_ratings = user_ratings.cache()\n",
    "\n",
    "# Create a data frame with all the ratings\n",
    "ratings_df = spark.createDataFrame(ratings, ['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "client_ratings_df = ratings_df.filter(ratings_df.user_id == client_id).alias(\"client\")\n",
    "user_ratings_df = ratings_df.filter(ratings_df.user_id != client_id).alias(\"other\")\n",
    "movies_df = spark.createDataFrame(movies, ['id', 'name', 'genres'])\\\n",
    "    .select(\"id\", \"name\").alias(\"movies\")\n",
    "\n",
    "#####################################\n",
    "print(\"user_ratings_df:\")\n",
    "#user_ratings_df.show(5)\n",
    "\n",
    "# Join the movies watched by the client and the other user\n",
    "aaa = user_ratings_df.join(client_ratings_df, on = \"movie_id\", how = \"inner\")\n",
    "\n",
    "# Determine the rating distance for each user/movie pair, and normalize it\n",
    "aaa = aaa.select(\\\n",
    "                 col(\"client.user_id\").alias(\"sim_client_user_id\"),\\\n",
    "                 col(\"other.user_id\").alias(\"sim_other_user_id\"),\\\n",
    "                 \"movie_id\",\\\n",
    "                 (abs(col(\"client.rating\") - col(\"other.rating\")) - RATING_RANGE / 2).alias(\"rating_dist_norm\")\\\n",
    "                )\n",
    "\n",
    "#####################################\n",
    "print(\"aaa:\")\n",
    "#aaa.show(5)\n",
    "\n",
    "# For each client, calculate the similarity to the other users\n",
    "users_similarity = aaa.groupBy(\"sim_client_user_id\", \"sim_other_user_id\")\\\n",
    "    .agg(sum(\"rating_dist_norm\").alias(\"similarity\")).alias(\"similarity\")\n",
    "    \n",
    "#####################################\n",
    "print(\"users_similarity:\")\n",
    "#users_similarity = users_similarity.cache()\n",
    "#users_similarity.show(5)\n",
    "\n",
    "## Create a list of users\n",
    "print(\"Creating list of users...\")\n",
    "user_list_df = ratings_df.select(col(\"user_id\").alias(\"list_user_id\")).distinct()\n",
    "# TODO: Do not limit to 1 in production!!!\n",
    "user_list_df = user_list_df.where(col(\"list_user_id\") == users_similarity.first().sim_client_user_id)\n",
    "user_list_d = user_list_df.cache()\n",
    "\n",
    "#####################################\n",
    "print(\"user_list_df:\")\n",
    "#user_list_df.show(1)\n",
    "\n",
    "suggestions = user_list_df.join(\\\n",
    "                                movies_df.select(\\\n",
    "                                                 col(\"id\").alias(\"sug_movie_id\")\\\n",
    "                                                ),\\\n",
    "                                on = col(\"sug_movie_id\") != True,\\\n",
    "                                how = \"inner\")\n",
    "\n",
    "#####################################\n",
    "print(\"suggestions:\")\n",
    "#suggestions.show(5)\n",
    "\n",
    "suggestions = suggestions.join(user_ratings_df,\\\n",
    "                               on = [col(\"sug_movie_id\") == col(\"movie_id\"),\\\n",
    "                                     col(\"list_user_id\") != col(\"user_id\")],\\\n",
    "                               how = \"inner\")\n",
    "\n",
    "######################################\n",
    "print(\"suggestions2:\")\n",
    "#suggestions.show(5)\n",
    "\n",
    "suggestions = suggestions.join(\\\n",
    "                               users_similarity,\\\n",
    "                               on = [col(\"list_user_id\") == col(\"sim_client_user_id\"),\\\n",
    "                                    col(\"user_id\") == col(\"sim_other_user_id\")],\\\n",
    "                              how = \"inner\")\n",
    "\n",
    "#####################################\n",
    "print(\"suggestions3:\")\n",
    "#suggestions = suggestions.cache()\n",
    "#suggestions.show(10)\n",
    "\n",
    "suggestions = suggestions.select(\"*\", (col(\"rating\") * col(\"similarity\")).alias(\"rating_mul\"))\n",
    "\n",
    "#####################################\n",
    "print(\"suggestions4:\")\n",
    "#suggestions = suggestions.cache()\n",
    "#suggestions.show(10)\n",
    "\n",
    "suggestions = suggestions\\\n",
    "    .groupBy(\"list_user_id\", \"sug_movie_id\")\\\n",
    "    .agg((ceil((sum(\"rating_mul\") / sum(\"similarity\")) * 2) / 2).alias(\"rating_norm\"))\n",
    "\n",
    "#####################################\n",
    "print(\"suggestions5:\")\n",
    "#suggestions = suggestions.cache()\n",
    "#suggestions.show(10)\n",
    "\n",
    "#suggestions = suggestions\\\n",
    "#    .select(\"*\")\\\n",
    "#    .groupBy(\"list_user_id\", \"sug_movie_id\")\\\n",
    "#    .agg((col(\"rating_mul\") / col(\"similarity_total\")).alias(\"rating_norm\"))\n",
    "#    \n",
    "######################################\n",
    "print(\"suggestions6:\")\n",
    "#suggestions = suggestions.cache()\n",
    "#suggestions.show(10)\n",
    "\n",
    "# TODO: Filter movies that have been watched already here\n",
    "\n",
    "\n",
    "\n",
    "#unwatched.filter(client_ratings_df\\\n",
    "#                 .select(client_ratings_df.movie_id)\\\n",
    "#                 .where(client_ratings_df.movie_id == unwatched.id)\\\n",
    "#                 .limit(1)\\\n",
    "#                 .count() == 0)\n",
    "\n",
    "\n",
    "suggestions.sort(desc(\"rating_norm\")).show(10000)\n",
    "\n",
    "print(\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file  ./ratings_full.csv ...\n",
      "Loading file  ./ratings_small.csv ...\n",
      "Loading file  ./movies_full.csv ...\n",
      "Loading file  ./movies_small.csv ...\n",
      "Parsing datasets...\n",
      "There are 24404096 ratings in the dataset.\n",
      "There are 100004 ratings in the small dataset.\n",
      "There are 40110 movies in the dataset.\n",
      "There are 9125 movies in the small dataset.\n",
      "Start training with small dataset...\n",
      "For rank 4 the RMSE is 0.9405925542574993\n",
      "For rank 8 the RMSE is 0.9451745059144596\n",
      "For rank 12 the RMSE is 0.9435903947376889\n",
      "The best model was trained with rank 4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "# Some constants\n",
    "DATASET_RATINGS_PATH = \"./ratings_full.csv\"\n",
    "DATASET_RATINGS_SMALL_PATH = \"./ratings_small.csv\"\n",
    "DATASET_MOVIES_PATH = \"./movies_full.csv\"\n",
    "DATASET_MOVIES_SMALL_PATH = \"./movies_small.csv\"\n",
    "\n",
    "# Define some helper functions\n",
    "def readCSV(fname, removeHeader=False, separator=','):\n",
    "    print(\"Loading file \", fname, \"...\")\n",
    "    rdd = sc.textFile(fname)\n",
    "    if removeHeader:\n",
    "        firstline = rdd.first()\n",
    "        rdd = rdd.filter(lambda x: x != firstline)\n",
    "    return rdd.map(lambda x: x.split(separator))\n",
    "\n",
    "# Load the ratings data\n",
    "ratings_data = readCSV(DATASET_RATINGS_PATH, removeHeader=True)\n",
    "small_ratings_data = readCSV(DATASET_RATINGS_SMALL_PATH, removeHeader=True)\n",
    "\n",
    "# Load the movies data\n",
    "movies_data = readCSV(DATASET_MOVIES_PATH, removeHeader=True)\n",
    "small_movies_data = readCSV(DATASET_MOVIES_SMALL_PATH, removeHeader=True)\n",
    "\n",
    "print(\"Parsing datasets...\")\n",
    "\n",
    "# Parse the ratings data\n",
    "# [user_id, movie_id, rating, timestamp] -> (user_id, movie_id, rating)\n",
    "ratings_data = ratings_data.map(lambda x: tuple(x[:-1]))\\\n",
    "    .cache()\n",
    "print(\"There are\", ratings_data.count(), \"ratings in the full dataset.\")\n",
    "      \n",
    "small_ratings_data = small_ratings_data.map(lambda x: tuple(x[:-1]))\\\n",
    "    .cache()\n",
    "print(\"There are\", small_ratings_data.count(), \"ratings in the small dataset.\")\n",
    "\n",
    "# Parse the movies data\n",
    "# [id, title, genres[]] -> (id, title)\n",
    "movies_data = movies_data.map(lambda x: tuple(x[:-1]))\\\n",
    "    .cache()\n",
    "print(\"There are\", movies_data.count(), \"movies in the full dataset.\")\n",
    "      \n",
    "small_movies_data = small_movies_data.map(lambda x: tuple(x[:-1]))\\\n",
    "    .cache()\n",
    "print(\"There are\", small_movies_data.count(), \"movies in the small dataset.\")\n",
    "\n",
    "print(\"Start training with small dataset...\")\n",
    "\n",
    "# Create some training sets based on the small data\n",
    "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "# Define some machine learning parameters\n",
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print(\"For rank\", rank, \"the RMSE is\", error)\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print(\"The best model was trained with rank\", best_rank)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dataset files...\n",
      "Loading file ./ratings_full.csv ...\n",
      "Loading file ./ratings_small.csv ...\n",
      "Loading file ./movies_full.csv ...\n",
      "Loading file ./movies_small.csv ...\n",
      "Datasets loaded, took 0.07 s \n",
      "\n",
      "Parsing datasets...\n",
      "There are 24404096 ratings in the complete dataset.\n",
      "There are 100004 ratings in the small dataset.\n",
      "There are 40110 movies in the complete dataset.\n",
      "There are 9125 movies in the small dataset.\n",
      "Parsing took 23.44 s \n",
      "\n",
      "Calibrating by training on small dataset...\n",
      "Training small dataset with rank 4 which has RMSE: 0.9405925542574993\n",
      "Training small dataset with rank 8 which has RMSE: 0.9451745059144596\n",
      "Training small dataset with rank 12 which has RMSE: 0.9435903947376889\n",
      "Trained small dataset calibration, took 3.97 s  with a best rank: 4 \n",
      "\n",
      "Training complete dataset...\n",
      "Training took 39.51 s \n",
      "\n",
      "Testing trained complete dataset...\n",
      "Trained complete dataset test, took 110.73 s  with an RMSE: 0.8318525567660949 \n",
      "\n",
      "Calculate movie ratings amount...\n",
      "Calculation done, took 0.01 s \n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "from time import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Configuration.                       #\n",
    "########################################\n",
    "\n",
    "# Paths to the available data sets\n",
    "DATASET_RATINGS_PATH = \"./ratings_full.csv\"\n",
    "DATASET_RATINGS_SMALL_PATH = \"./ratings_small.csv\"\n",
    "DATASET_MOVIES_PATH = \"./movies_full.csv\"\n",
    "DATASET_MOVIES_SMALL_PATH = \"./movies_small.csv\"\n",
    "\n",
    "# The minimum number of reviews a movie must have, to recommend it reliably\n",
    "REVIEW_MIN_AMOUNT = 20\n",
    "\n",
    "# Split ratio for the small training/calibration data\n",
    "TRAIN_SMALL_SPLIT = [6, 2, 2]\n",
    "\n",
    "# Split ratio for the complete training data\n",
    "TRAIN_COMPLETE_SPLIT = [7, 3]\n",
    "\n",
    "# Seed to use for training\n",
    "TRAIN_SEED = 5\n",
    "\n",
    "# Ranks to use for training\n",
    "TRAIN_RANKS = [4, 6, 8, 10, 12]\n",
    "\n",
    "# Number of iterations to train for\n",
    "TRAIN_ITERATIONS = 10\n",
    "\n",
    "# The number of movies to recommend for the user\n",
    "RECOMMENDATION_AMOUNT = 10\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Function definitions.                #\n",
    "########################################\n",
    "\n",
    "# Define some helper functions\n",
    "def readCSV(fname, removeHeader=False, separator=','):\n",
    "    print(\"Loading file\", fname, \"...\")\n",
    "    rdd = sc.textFile(fname)\n",
    "    if removeHeader:\n",
    "        firstline = rdd.first()\n",
    "        rdd = rdd.filter(lambda x: x != firstline)\n",
    "    return rdd.map(lambda x: x.split(separator))\n",
    "\n",
    "# Benchmark time\n",
    "global benchmark\n",
    "\n",
    "# Reset the benchmark\n",
    "def benchmark_reset():\n",
    "    global benchmark\n",
    "    benchmark = time()\n",
    "    \n",
    "# Get the benchmarked value\n",
    "def benchmark_get():\n",
    "    global benchmark\n",
    "    return str(round(time() - benchmark, 2)) + \" s\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Load datasets.                       #\n",
    "########################################\n",
    "\n",
    "print(\"Loading all dataset files...\")\n",
    "benchmark_reset()\n",
    "\n",
    "# Load the ratings data\n",
    "ratings_data = readCSV(DATASET_RATINGS_PATH, removeHeader=True)\n",
    "small_ratings_data = readCSV(DATASET_RATINGS_SMALL_PATH, removeHeader=True)\n",
    "\n",
    "# Load the movies data\n",
    "movies_data = readCSV(DATASET_MOVIES_PATH, removeHeader=True)\n",
    "small_movies_data = readCSV(DATASET_MOVIES_SMALL_PATH, removeHeader=True)\n",
    "\n",
    "print(\"Datasets loaded, took\", benchmark_get(), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Parse datasets.                      #\n",
    "########################################\n",
    "\n",
    "print(\"Parsing datasets...\")\n",
    "benchmark_reset()\n",
    "\n",
    "# Parse the complete ratings set\n",
    "# [user_id, movie_id, rating, timestamp] -> (user_id, movie_id, rating)\n",
    "ratings_data = ratings_data.map(lambda x: (int(x[0]), int(x[1]), float(x[2])))\\\n",
    "    .cache()\n",
    "print(\"There are\", ratings_data.count(), \"ratings in the complete dataset.\")\n",
    "\n",
    "# Parse the small ratings set\n",
    "small_ratings_data = small_ratings_data.map(lambda x: (int(x[0]), int(x[1]), float(x[2])))\\\n",
    "    .cache()\n",
    "print(\"There are\", small_ratings_data.count(), \"ratings in the small dataset.\")\n",
    "\n",
    "# Parse the complete movies set\n",
    "# [id, title, genres[]] -> (id, title)\n",
    "movies_data = movies_data.map(lambda x: (int(x[0]), x[1]))\\\n",
    "    .cache()\n",
    "print(\"There are\", movies_data.count(), \"movies in the complete dataset.\")\n",
    "      \n",
    "# Parse the small ratings set\n",
    "small_movies_data = small_movies_data.map(lambda x: (int(x[0]), x[1]))\\\n",
    "    .cache()\n",
    "print(\"There are\", small_movies_data.count(), \"movies in the small dataset.\")\n",
    "\n",
    "print(\"Parsing took\", benchmark_get(), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Calibrate machine learning.          #\n",
    "########################################\n",
    "\n",
    "print(\"Calibrating by training on small dataset...\")\n",
    "benchmark_reset()\n",
    "\n",
    "# Some parameters\n",
    "regularization_parameter = 0.1\n",
    "errors = [0] * len(TRAIN_RANKS)\n",
    "err = 0\n",
    "\n",
    "# Create some training sets based on the small data\n",
    "training_set, validation_set, test_set = small_ratings_data\\\n",
    "        .randomSplit(TRAIN_SMALL_SPLIT, seed = 0)\n",
    "prediction_validation = validation_set\\\n",
    "        .map(lambda x: tuple(x[0:2]))\n",
    "prediction_test = test_set\\\n",
    "        .map(lambda x: tuple(x[0:2]))\n",
    "\n",
    "# Rememer the minimum error value, best rank and iteration\n",
    "min_error = float(\"inf\")\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "\n",
    "# Loop through each rank to train\n",
    "for rank in TRAIN_RANKS:\n",
    "    # Train on the selected rank\n",
    "    model = ALS.train(training_set,\\\n",
    "                      rank,\\\n",
    "                      seed = TRAIN_SEED,\\\n",
    "                      iterations = TRAIN_ITERATIONS,\\\n",
    "                      lambda_ = regularization_parameter)\n",
    "    \n",
    "    # Make some predictions to test\n",
    "    predictions = model\\\n",
    "            .predictAll(prediction_validation)\\\n",
    "            .map(lambda x: ((x[0], x[1]), x[2]))\n",
    "    rating_predictions = validation_set\\\n",
    "            .map(lambda x: ((int(x[0]), int(x[1])), float(x[2])))\\\n",
    "            .join(predictions)\n",
    "            \n",
    "    # Calculate the predeiction error value, and store it\n",
    "    error = math.sqrt(rating_predictions\\\n",
    "                      .map(lambda x: (x[1][0] - x[1][1])**2)\\\n",
    "                      .mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    \n",
    "    # Update the minimum error value and the best rank\n",
    "    print(\"Training small dataset with rank\", rank, \"which has RMSE:\", error)\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print(\"Trained small dataset calibration, took\", benchmark_get(), \" with a best rank:\", best_rank, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Train on complete dataset.           #\n",
    "########################################\n",
    "\n",
    "print(\"Training complete dataset...\")\n",
    "benchmark_reset()\n",
    "\n",
    "# Randomly split the data, to use for training and testing\n",
    "training_set, test_set = ratings_data.randomSplit(TRAIN_COMPLETE_SPLIT,\\\n",
    "                                                  seed = 0)\n",
    "\n",
    "# Train using the data sets\n",
    "trained_model = ALS.train(training_set,\\\n",
    "                           best_rank,\\\n",
    "                           seed = TRAIN_SEED,\\\n",
    "                           iterations = TRAIN_ITERATIONS,\\\n",
    "                           lambda_ = regularization_parameter)\n",
    "\n",
    "print(\"Training took\", benchmark_get(), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Test trained data.                   #\n",
    "########################################\n",
    "\n",
    "print(\"Testing trained complete dataset...\")\n",
    "benchmark_reset()\n",
    "\n",
    "# Create a test prediction set\n",
    "test_predict_set = test_set.map(lambda x: tuple(x[0:2]))\n",
    "\n",
    "# Make come predictions to test\n",
    "predictions = trained_model\\\n",
    "        .predictAll(test_predict_set)\\\n",
    "        .map(lambda x: (tuple(x[0:2]), x[2]))\n",
    "rates_predictions = test_set\\\n",
    "        .map(lambda x: ((int(x[0]), int(x[1])), float(x[2])))\\\n",
    "        .join(predictions)\n",
    "\n",
    "# Calculate the error value\n",
    "error = math.sqrt(\\\n",
    "                  rates_predictions\\\n",
    "                          .map(lambda x: (x[1][0] - x[1][1])**2)\\\n",
    "                          .mean())\n",
    "    \n",
    "print(\"Trained complete dataset test, took\", benchmark_get(), \" with an RMSE:\", error, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Calculate movie review count.        #\n",
    "########################################\n",
    "\n",
    "print(\"Calculate movie ratings amount...\")\n",
    "benchmark_reset()\n",
    "\n",
    "# Helper method to count the number of ratings for each movie\n",
    "def calc_avg_count(id_ratings):\n",
    "    number = len(id_ratings[1])\n",
    "    return id_ratings[0],\\\n",
    "        (number, float(sum(x for x in id_ratings[1])) / number)\n",
    "\n",
    "# Count the number of ratings per movie\n",
    "movie_id_ratings = (ratings_data\\\n",
    "                            .map(lambda x: (x[1], x[2]))\\\n",
    "                            .groupByKey())\n",
    "movie_id_ratings_avg = movie_id_ratings.map(calc_avg_count)\n",
    "movie_id_ratings_count = movie_id_ratings_avg.map(lambda x: (x[0], x[1][0]))\n",
    "\n",
    "print(\"Calculation done, took\", benchmark_get(), \"\\n\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie recommendations:\n",
      "Predicting top movies for user 1 ...\n",
      "Top movies predicted, took 13.27 s\n",
      "('The Adventures of Sherlock Holmes and Doctor Watson: King of Blackmailers (1980)', 5.171305424121109, 26)('\"Crucified Lovers', 5.102902195867642, 21)('Napoléon (1927)', 5.0639180907073955, 28)('Promises (2001)', 5.0509586479029895, 148)('\"Personal Journey with Martin Scorsese Through American Movies', 4.975808456516342, 33)('Touki Bouki (1973)', 4.972044433527637, 41)('Stations of the Cross (2014)', 4.935984917817181, 20)('Landscape in the Mist (Topio stin omichli) (1988)', 4.909311548773586, 40)('\"Bonheur', 4.901570823758208, 99)('State of Siege (État de siège) (1972)', 4.901173313419776, 28)\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Function definitions.                #\n",
    "########################################\n",
    "\n",
    "# Predict the ratings for all movies the user hasn't rated yet.\n",
    "#\n",
    "# Parameters:\n",
    "# - user_id: The ID of the user to predict ratings for.\n",
    "#\n",
    "# Returns movie rating predictions.\n",
    "def predict_movie_ratings(user_id):\n",
    "    # Create a list of IDs of movies already rated by the user\n",
    "    rated_ids = ratings_data\\\n",
    "            .filter(lambda x: x[0] == user_id)\\\n",
    "            .map(lambda x: x[0])\\\n",
    "            .collect()\n",
    "\n",
    "    # Get all movie IDs that haven't been rated by the user\n",
    "    unrated_ids = (movies_data\\\n",
    "                       .filter(lambda x: x[0] not in rated_ids)\\\n",
    "                       .map(lambda x: (user_id, x[0])))\n",
    "\n",
    "    # Predict the recommendation value for all unrated movies for this user\n",
    "    predictions = trained_model.predictAll(unrated_ids)\n",
    "\n",
    "    # Transform the prediction result into proper tuples\n",
    "    # (movie_id, predicted_rating)\n",
    "    predictions = predictions.map(lambda x: (x.product, x.rating))\n",
    "    \n",
    "    # Saturate the list of tuples with the movie titles and number of ratings\n",
    "    predictions = predictions\\\n",
    "            .join(movies_data)\\\n",
    "            .join(movie_id_ratings_count)\n",
    "\n",
    "    # Remap the recommendations to get usable tuples:\n",
    "    # (title, predicted_rating, rating_count)\n",
    "    return predictions\\\n",
    "            .map(lambda x: (x[1][0][1], x[1][0][0], x[1][1]))\n",
    "\n",
    "        \n",
    "        \n",
    "# Predict the top movies to watch for the given user.\n",
    "#\n",
    "# Parameters:\n",
    "# - user_id: The ID of the user to predict movies for.\n",
    "def predict_top_movies(user_id):\n",
    "    # Print a status message\n",
    "    print(\"Predicting top movies for user\", user_id, \"...\")\n",
    "    benchmark_reset()\n",
    "\n",
    "    # Predict ratings for unwatched movies for this user\n",
    "    predictions = predict_movie_ratings(user_id)\n",
    "    \n",
    "    # Filter movies that have less ratings than the specified constraint\n",
    "    predictions = predictions\\\n",
    "            .filter(lambda x: x[2] >= REVIEW_MIN_AMOUNT)\n",
    "    \n",
    "    # Take the top list of movies for the user as a list\n",
    "    top_movies = predictions.takeOrdered(RECOMMENDATION_AMOUNT,\\\n",
    "                            key = lambda x: -x[1])\n",
    "    \n",
    "    # Print the benchmark time, and return the top movies\n",
    "    print(\"Top movies predicted, took\", benchmark_get())\n",
    "    return top_movies\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Recommendation process.              #\n",
    "########################################\n",
    "\n",
    "# Get the first user, to recommend movies for\n",
    "selected_user = ratings_data.first()[0]\n",
    "\n",
    "# Print the recommended movies for the selected user\n",
    "print(\"Movie recommendations:\")\n",
    "print(\"\".join(map(str, predict_top_movies(selected_user))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dataset files...\n",
      "Loading file  ./ratings_full.csv ...\n",
      "Loading file  ./ratings_small.csv ...\n",
      "Loading file  ./movies_full.csv ...\n",
      "Loading file  ./movies_small.csv ...\n",
      "Parsing datasets...\n",
      "There are 24404096 ratings in the complete dataset.\n",
      "There are 100004 ratings in the small dataset.\n",
      "There are 40110 movies in the complete dataset.\n",
      "There are 9125 movies in the small dataset.\n",
      "Calibrating by training on small dataset...\n",
      "Training small dataset with rank 4 which has RMSE: 0.9393526035943128\n",
      "Training small dataset with rank 8 which has RMSE: 0.9437873274872436\n",
      "Training small dataset with rank 10 which has RMSE: 0.938198826757663\n",
      "Training small dataset with rank 12 which has RMSE: 0.9430925559243571\n",
      "Trained small dataset calibration, best rank: 10\n",
      "Training complete dataset...\n",
      "Testing trained complete dataset...\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "from time import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Configuration.                       #\n",
    "########################################\n",
    "\n",
    "# Paths to the available data sets\n",
    "DATASET_RATINGS_PATH = \"./ratings_full.csv\"\n",
    "DATASET_RATINGS_SMALL_PATH = \"./ratings_small.csv\"\n",
    "DATASET_MOVIES_PATH = \"./movies_full.csv\"\n",
    "DATASET_MOVIES_SMALL_PATH = \"./movies_small.csv\"\n",
    "\n",
    "# The minimum number of reviews a movie must have, to recommend it reliably\n",
    "REVIEW_MIN_AMOUNT = 20\n",
    "\n",
    "# Split ratio for the small training/calibration data\n",
    "TRAIN_SMALL_SPLIT = [6, 2, 2]\n",
    "\n",
    "# Split ratio for the complete training data\n",
    "TRAIN_COMPLETE_SPLIT = [7, 3]\n",
    "\n",
    "# Seed to use for training\n",
    "TRAIN_SEED = 5\n",
    "\n",
    "# Ranks to use for training\n",
    "TRAIN_RANKS = [4, 6, 8, 10, 12]\n",
    "\n",
    "# Number of iterations to train for\n",
    "TRAIN_ITERATIONS = 16\n",
    "\n",
    "# The number of movies to recommend for the user\n",
    "RECOMMENDATION_AMOUNT = 10\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Function definitions.                #\n",
    "########################################\n",
    "\n",
    "# Define some helper functions\n",
    "def readCSV(fname, removeHeader=False, separator=','):\n",
    "    print(\"Loading file\", fname, \"...\")\n",
    "    rdd = sc.textFile(fname)\n",
    "    if removeHeader:\n",
    "        firstline = rdd.first()\n",
    "        rdd = rdd.filter(lambda x: x != firstline)\n",
    "    return rdd.map(lambda x: x.split(separator))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Load datasets.                       #\n",
    "########################################\n",
    "\n",
    "print(\"Loading all dataset files...\")\n",
    "\n",
    "# Load the ratings data\n",
    "ratings_data = readCSV(DATASET_RATINGS_PATH, removeHeader=True)\n",
    "small_ratings_data = readCSV(DATASET_RATINGS_SMALL_PATH, removeHeader=True)\n",
    "\n",
    "# Load the movies data\n",
    "movies_data = readCSV(DATASET_MOVIES_PATH, removeHeader=True)\n",
    "small_movies_data = readCSV(DATASET_MOVIES_SMALL_PATH, removeHeader=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Parse datasets.                      #\n",
    "########################################\n",
    "\n",
    "print(\"Parsing datasets...\")\n",
    "\n",
    "# Parse the complete ratings set\n",
    "# [user_id, movie_id, rating, timestamp] -> (user_id, movie_id, rating)\n",
    "ratings_data = ratings_data.map(lambda x: (int(x[0]), int(x[1]), float(x[2])))\\\n",
    "    .cache()\n",
    "print(\"There are\", ratings_data.count(), \"ratings in the complete dataset.\")\n",
    "\n",
    "# Parse the small ratings set\n",
    "small_ratings_data = small_ratings_data.map(lambda x: (int(x[0]), int(x[1]), float(x[2])))\\\n",
    "    .cache()\n",
    "print(\"There are\", small_ratings_data.count(), \"ratings in the small dataset.\")\n",
    "\n",
    "# Parse the complete movies set\n",
    "# [id, title, genres[]] -> (id, title)\n",
    "movies_data = movies_data.map(lambda x: (int(x[0]), x[1]))\\\n",
    "    .cache()\n",
    "print(\"There are\", movies_data.count(), \"movies in the complete dataset.\")\n",
    "      \n",
    "# Parse the small ratings set\n",
    "small_movies_data = small_movies_data.map(lambda x: (int(x[0]), x[1]))\\\n",
    "    .cache()\n",
    "print(\"There are\", small_movies_data.count(), \"movies in the small dataset.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Calibrate machine learning.          #\n",
    "########################################\n",
    "\n",
    "print(\"Calibrating by training on small dataset...\")\n",
    "\n",
    "# Some parameters\n",
    "regularization_parameter = 0.1\n",
    "errors = [0] * len(TRAIN_RANKS)\n",
    "err = 0\n",
    "\n",
    "# Create some training sets based on the small data\n",
    "training_set, validation_set, test_set = small_ratings_data\\\n",
    "        .randomSplit(TRAIN_SMALL_SPLIT, seed = 0)\n",
    "prediction_validation = validation_set\\\n",
    "        .map(lambda x: tuple(x[0:2]))\n",
    "prediction_test = test_set\\\n",
    "        .map(lambda x: tuple(x[0:2]))\n",
    "\n",
    "# Rememer the minimum error value, best rank and iteration\n",
    "min_error = float(\"inf\")\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "\n",
    "# Loop through each rank to train\n",
    "for rank in TRAIN_RANKS:\n",
    "    # Train on the selected rank\n",
    "    model = ALS.train(training_set,\\\n",
    "                      rank,\\\n",
    "                      seed = TRAIN_SEED,\\\n",
    "                      iterations = TRAIN_ITERATIONS,\\\n",
    "                      lambda_ = regularization_parameter)\n",
    "    \n",
    "    # Make some predictions to test\n",
    "    predictions = model\\\n",
    "            .predictAll(prediction_validation)\\\n",
    "            .map(lambda x: (tuple(x[0:2]), x[2]))\n",
    "    rates_predictions = validation_set\\\n",
    "            .map(lambda x: ((int(x[0]), int(x[1])), float(x[2])))\\\n",
    "            .join(predictions)\n",
    "            \n",
    "    # Calculate the predeiction error value, and store it\n",
    "    error = math.sqrt(rates_predictions\\\n",
    "                      .map(lambda x: (x[1][0] - x[1][1]) ** 2)\\\n",
    "                      .mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    \n",
    "    # Update the minimum error value and the best rank\n",
    "    print(\"Training small dataset with rank\", rank, \"which has RMSE:\", error)\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print(\"Trained small dataset calibration, best rank:\", best_rank)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Train on complete dataset.           #\n",
    "########################################\n",
    "\n",
    "print(\"Training complete dataset...\")\n",
    "\n",
    "# Randomly split the data, to use for training and testing\n",
    "training_set, test_set = ratings_data.randomSplit(TRAIN_COMPLETE_SPLIT,\\\n",
    "                                                  seed = 0)\n",
    "\n",
    "# Train using the data sets\n",
    "trained_model = ALS.train(training_set,\\\n",
    "                           best_rank,\\\n",
    "                           seed = seed,\\\n",
    "                           iterations = iterations,\\\n",
    "                           lambda_ = regularization_parameter)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Test trained data.                   #\n",
    "########################################\n",
    "\n",
    "print(\"Testing trained complete dataset...\")\n",
    "\n",
    "# Create a test prediction set\n",
    "test_predict_set = test_set.map(lambda x: tuple(x[0:2]))\n",
    "\n",
    "# Make come predictions to test\n",
    "predictions = trained_model\\\n",
    "        .predictAll(test_predict_set)\\\n",
    "        .map(lambda x: (tuple(x[0:2]), x[2]))\n",
    "rates_predictions = test_set\\\n",
    "        .map(lambda x: ((int(x[0]), int(x[1])), float(x[2])))\\\n",
    "        .join(predictions)\n",
    "\n",
    "# Calculate the error value\n",
    "error = math.sqrt(\\\n",
    "                  rates_predictions\\\n",
    "                          .map(lambda x: (x[1][0] - x[1][1]) ** 2)\\\n",
    "                          .mean())\n",
    "    \n",
    "print(\"Trained complete dataset test, RMSE:\", error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Calculate movie review count.        #\n",
    "########################################\n",
    "\n",
    "# Helper method to count the number of ratings for each movie\n",
    "def calc_avg_count(id_ratings):\n",
    "    number = len(id_ratings[1])\n",
    "    return id_ratings[0],\\\n",
    "        (number, float(sum(x for x in id_ratings[1])) / number)\n",
    "\n",
    "# Count the number of ratings per movie\n",
    "movie_id_ratings = (ratings_data\\\n",
    "                            .map(lambda x: (x[1], x[2]))\\\n",
    "                            .groupByKey())\n",
    "movie_id_ratings_avg = movie_id_ratings.map(calc_avg_count)\n",
    "movie_id_ratings_count = movie_id_ratings_avg.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies for user 1 :\n",
      "Processing movies for user 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RECOMMENDATION_AMOUNT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-526172bb31e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recommended movies for user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_top_movies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_user\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-526172bb31e4>\u001b[0m in \u001b[0;36mpredict_top_movies\u001b[0;34m(user_id)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Take the top list of movies for the user as a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtakeOrdered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRECOMMENDATION_AMOUNT\u001b[0m\u001b[0;34m,\u001b[0m                            \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RECOMMENDATION_AMOUNT' is not defined"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Function definitions.                #\n",
    "########################################\n",
    "\n",
    "# Predict the ratings for all movies the user hasn't rated yet.\n",
    "#\n",
    "# Parameters:\n",
    "# - user_id: The ID of the user to predict ratings for.\n",
    "#\n",
    "# Returns movie rating predictions.\n",
    "def predict_movie_ratings(user_id):\n",
    "    # Create a list of IDs of movies already rated by the user\n",
    "    rated_ids = ratings_data\\\n",
    "            .filter(lambda x: x[0] == user_id)\\\n",
    "            .map(lambda x: x[0])\\\n",
    "            .collect()\n",
    "\n",
    "    # Get all movie IDs that haven't been rated by the user\n",
    "    unrated_ids = (movies_data\\\n",
    "                       .filter(lambda x: x[0] not in rated_ids)\\\n",
    "                       .map(lambda x: (user_id, x[0])))\n",
    "\n",
    "    # Predict the recommendation value for all unrated movies for this user\n",
    "    predictions = trained_model.predictAll(unrated_ids)\n",
    "\n",
    "    # Transform the prediction result into proper tuples\n",
    "    # (movie_id, predicted_rating)\n",
    "    predictions = predictions.map(lambda x: (x.product, x.rating))\n",
    "    \n",
    "    # Saturate the list of tuples with the movie titles and number of ratings\n",
    "    predictions = predictions\\\n",
    "            .join(movies_data)\\\n",
    "            .join(movie_id_ratings_count)\n",
    "\n",
    "    # Remap the recommendations to get usable tuples:\n",
    "    # (title, predicted_rating, rating_count)\n",
    "    return predictions\\\n",
    "            .map(lambda x: (x[1][0][1], x[1][0][0], x[1][1]))\n",
    "\n",
    "        \n",
    "        \n",
    "# Predict the top movies to watch for the given user.\n",
    "#\n",
    "# Parameters:\n",
    "# - user_id: The ID of the user to predict movies for.\n",
    "def predict_top_movies(user_id):\n",
    "    # Print a status message\n",
    "    print(\"Processing movies for user\", user_id)\n",
    "\n",
    "    # Predict ratings for unwatched movies for this user\n",
    "    predictions = predict_movie_ratings(user_id)\n",
    "    \n",
    "    # Filter movies that have less ratings than the specified constraint\n",
    "    predictions = predictions\\\n",
    "            .filter(lambda x: x[2] >= REVIEW_MIN_AMOUNT)\n",
    "    \n",
    "    # Take the top list of movies for the user as a list\n",
    "    return predictions.takeOrdered(RECOMMENDATION_AMOUNT,\\\n",
    "                            key = lambda x: -x[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Recommendation process.              #\n",
    "########################################\n",
    "\n",
    "# Get the first user, to recommend movies for\n",
    "selected_user = ratings_data.first()[0]\n",
    "\n",
    "# Print the recommended movies for the selected user\n",
    "print(\"Recommended movies for user\", selected_user, \":\")\n",
    "print(\"\".join(map(str, predict_top_movies(selected_user))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
